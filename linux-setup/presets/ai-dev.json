{
  "name": "Local LLM Environment",
  "category": "AI",
  "description": "Ollama engine, Models, and Open WebUI (No Python required)",
  "modules": [
    { "id": "dev.docker" },
    { "id": "dev.ollama" },
    { "id": "dev.ollama-models", "params": { "version": "llama3.1" } },
    { "id": "dev.ollama-models", "params": { "version": "phi3", "selected": false } },
    { "id": "dev.open-webui" },
    { "id": "dev.nvidia-setup", "params": { "selected": false } }
  ]
}
